predictable s3 bucket names

We recommend that all bucket names comply with DNS naming conventions. These conventions are enforced in all regions except for the US East (N. Virginia) region. If you use the AWS management console, bucket names must be DNS compliant in all regions.

You can configure lifecycle on your bucket to expire objects, Amazon S3 then deletes expired objects.

mybucket.s3-accelerate.amazonaws.com

When the requester assumes an AWS Identity and Access Management (IAM) role prior to making their request, the account to which the role belongs is charged for the request. For more information about IAM roles, see IAM Roles in the IAM User Guide.

Note that your Amazon S3 resources (for example buckets and objects) are private by default

You can set object metadata at the time you upload it. After you upload the object, you cannot modify object metadata. The only way to modify object metadata is to make a copy of the object and set the metadata.

The following characters in a key name may require additional code handling and will likely need to be URL encoded or referenced as HEX. Some of these are non-printable characters and your browser may not handle them, which will also require special handl

You should avoid the following characters in a key name because of significant special handling for consistency across all applications.

There are two kinds of metadata: system metadata and user-defined metadata.

Versioning enables you to keep multiple versions of an object in one bucket, for example, my-image.jpg (version 111111) and my-image.jpg (version 222222) - hide malicious data as a particular version of a benign file?

An example version ID is 3/L4kqtJlcpXroDTDmJ+rmSpXd3dIbrHY+MTRCxf3vjVBH40Nr8X8gdRQBpUMLUo. Only Amazon S3 generates version IDs. They cannot be edited.

You can permanently delete an object by specifying the version you want to delete. Only the owner of an Amazon S3 bucket can permanently delete a version

If you notice a significant increase in the number of HTTP 503-slow down responses received for Amazon S3 PUT or DELETE object requests to a bucket that has versioning enabled, you might have one or more objects in the bucket for which there are millions of versions.

You can add tags to new objects when you upload them or you can add them to existing objects

Object tags enable fine-grained access control of permissions. For example, you could grant an IAM user permissions to read only objects with specific tags

Object tags enable fine-grained object lifecycle management in which you can specify tag-based filter, in addition to key name prefix, in a lifecycle rule

You can also customize Amazon CloudWatch metrics and AWS CloudTrail logs to display information by specific tag filters

While it is acceptable to use tags to label objects containing confidential data (such as, personally identifiable information (PII) or protected health information (PHI)), the tags themselves shouldn't contain any confidential information.

If you configured cross-region replication (CRR) on your bucket, Amazon S3 replicates tags, provided you grant S3 permission to read the tags

When you create objects using the multipart upload API operation, you can add tags to an object only after you complete the multipart upload (that is, after the object is created)

You can grant conditional permissions based on object tags.
s3:ExistingObjectTag/<tag-key> – Use this condition key to verify that an existing object tag has the specific tag key and value.
s3:RequestObjectTagKeys – Use this condition key to restrict the tag keys that you want to allow on objects. This is useful when adding tags to objects using the PutObjectTagging and PutObject, and POST object requests.
s3:RequestObjectTag/<tag-key> – Use this condition key to restrict the tag keys and values that you want to allow on objects. This is useful when adding tags to objects using the PutObjectTagging and PutObject, and POST Bucket requests.

Transition actions – In which you define when objects transition to another storage class. For example, you may choose to transition objects to the STANDARD_IA (IA, for infrequent access) storage class 30 days after creation, or archive objects to the GLACIER storage class one year after creation.

Expiration actions – In which you specify when the objects expire. Then Amazon S3 deletes the expired objects on your behalf.

Archived objects are Amazon S3 objects, but before you can access an archived object, you must first restore a temporary copy of it. The restored object copy is available only for the duration you specify in the restore request. After that, Amazon S3 deletes the temporary copy, and the object remains archived in Amazon Glacier.

 With CORS support in Amazon S3, you can build rich client-side web applications with Amazon S3 and selectively allow cross-origin access to your Amazon S3 resources.


You can add up to 100 rules to the configuration. You add the XML document as the cors subresource to the bucket either programmatically or by using the Amazon S3 console

ExposeHeader—Identifies the response headers (in this example, x-amz-server-side-encryption, x-amz-request-id, and x-amz-id-2) that customers will be able to access from their applications (for example, from a JavaScript XMLHttpRequest object).


 You can optionally specify * as the origin to enable all the origins to send cross-origin requests. You can also specify https to enable only secure origins

Amazon S3 enables you to store, retrieve, and delete objects. You can retrieve an entire object or a portion of an object.

However, the object owner can optionally share objects with others by creating a pre-signed URL, using their own security credentials, to grant time-limited permission to download the objects.


Deleting Objects from an MFA-Enabled Bucket








